{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting csv data from data/sp10/\n",
      "['ORCL.csv', 'EBAY.csv', 'INTU.csv', 'INTC.csv', 'ADSK.csv', 'FB.csv', 'SYMC.csv', 'NFLX.csv', 'GOOGL.csv', 'AAPL.csv']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from utils import dataUtil\n",
    "\n",
    "N = 10 # depend on the N previous periods\n",
    "B = 1 # batch size\n",
    "\n",
    "dateSelected, stockPrice  = dataUtil.getData()\n",
    "logreturn = dataUtil.logReturn(stockPrice)\n",
    "# return for N previous periods, input, shape: [-1,L,N]\n",
    "logReturn_x = dataUtil.logReturnMatrix(logreturn, N)\n",
    "# return for current period\n",
    "logReturn_x0 = logreturn[N:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = len(stockPrice[0]) # L stocks\n",
    "logReturn_x_data = tf.reshape(logReturn_x, [-1,L,N,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, L, N])\n",
    "x_data = tf.reshape(x, [-1,L,N,1]) # start from one channel\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, L])\n",
    "previousPortfolio = tf.placeholder(tf.float32, shape=[None, L]) # portfolio for last time step\n",
    "previousReturn = tf.placeholder(tf.float32, shape=[None]) # return for last time step\n",
    "\n",
    "# weight initialization\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convolution and pooling\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def avg_pool_4x1(x):\n",
    "    return tf.nn.avg_pool(x, ksize=[1, 1, 1, 1],\n",
    "                        strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first convolution layer\n",
    "W_conv1 = weight_variable([1, 3, 1, 10])\n",
    "b_conv1 = bias_variable([10])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_data, W_conv1) + b_conv1)\n",
    "h_pool1 = avg_pool_4x1(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# second convolutional layer\n",
    "W_conv2 = weight_variable([1, 3, 10, 5])\n",
    "b_conv2 = bias_variable([5])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = avg_pool_4x1(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Shape:0\", shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# densely connected layer 1\n",
    "wsize1 = int(h_pool2.shape[2] * h_pool2.shape[3])\n",
    "wsize2 = 1\n",
    "W_fc1 = weight_variable([wsize1, wsize2] )\n",
    "prePort = tf.reshape(previousPortfolio,[-1,1])\n",
    "W_fc12 = weight_variable([1, wsize2])\n",
    "\n",
    "b_fc1 = bias_variable([wsize2])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, wsize1])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + tf.matmul(prePort, W_fc12) + b_fc1)\n",
    "print tf.shape(h_fc1)\n",
    "h_fc1_score = tf.reshape(h_fc1, [-1, L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# densely connected layer 2 \n",
    "# readout layer\n",
    "W_fc2 = weight_variable([L, L])\n",
    "b_fc2 = bias_variable([L])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_score, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "currentPortfolio = tf.nn.softmax(logits=y_conv)\n",
    "\n",
    "reward0 = np.multiply(currentPortfolio, y_)\n",
    "reward = tf.reduce_sum(reward0, 1)\n",
    "\n",
    "# calculate return including transaction cost\n",
    "\n",
    "c = np.zeros(L+1) + 0.0001 # transaction cost coefficients\n",
    "\n",
    "flag = 0\n",
    "for j in xrange(L):\n",
    "    tmp = currentPortfolio[:,j]-previousPortfolio[:,j]*tf.divide(tf.exp(x[:,j,-1]),(1.0+previousReturn))\n",
    "    reward = reward - c[j+1] * np.abs(tmp)\n",
    "    if tmp != 0:\n",
    "        flag = 1\n",
    "if flag:\n",
    "    reward = reward - c[0]\n",
    "\n",
    "# loss function: reward_minus\n",
    "reward_minus = -tf.reduce_prod(reward+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(reward_minus)\n",
    "test_step = tf.train.AdamOptimizer(1e-4).minimize(reward_minus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.08916359558\n",
      "1.0898507924\n",
      "1.09056510265\n",
      "1.09141417651\n",
      "1.09242524314\n",
      "1.09362991616\n",
      "1.09506023897\n",
      "1.09675691194\n",
      "1.09876825154\n",
      "1.10115266591\n",
      "1.10398519296\n",
      "1.10735586483\n",
      "1.11137107485\n",
      "1.11615315294\n",
      "1.12184090435\n",
      "1.12858516249\n",
      "1.1365480829\n",
      "1.14591798947\n",
      "1.15691446619\n",
      "1.16977460221\n",
      "1.18471769751\n",
      "1.20190649339\n",
      "1.22141214148\n",
      "1.24319832787\n",
      "1.26710886178\n",
      "1.29285641102\n",
      "1.32004199431\n",
      "1.34819399659\n",
      "1.37681205859\n",
      "1.40542600503\n",
      "1.43361711668\n",
      "1.461051163\n",
      "1.48747072613\n",
      "1.51269557517\n",
      "1.53660608854\n",
      "1.55912569789\n",
      "1.58021797404\n",
      "1.59986591462\n",
      "1.61808138257\n",
      "1.63488847834\n",
      "1.65032704865\n",
      "1.66445102358\n",
      "1.6773228189\n",
      "1.6890144181\n",
      "1.69960298403\n",
      "1.70916830828\n",
      "1.71779240328\n",
      "1.72555646799\n",
      "1.73253700058\n",
      "1.73880966748\n",
      "1.74444316282\n",
      "1.74950329682\n",
      "1.75405090712\n",
      "1.75813613696\n",
      "1.76181282543\n",
      "1.76512303103\n",
      "1.76810653041\n",
      "1.7707972451\n",
      "1.77322799793\n",
      "1.77542813506\n",
      "1.77742063754\n",
      "1.77922859243\n",
      "1.78087050415\n",
      "1.78236340489\n",
      "1.78372387426\n",
      "1.78496474015\n",
      "1.78610069205\n",
      "1.78713736151\n",
      "1.78808748341\n",
      "1.78895875802\n",
      "1.78975933407\n",
      "1.79049574115\n",
      "1.79117342318\n",
      "1.79179844692\n",
      "1.79237509849\n",
      "1.79290799265\n",
      "1.79340070161\n",
      "1.79385729714\n",
      "1.79428021924\n",
      "1.79467249362\n",
      "1.79503752238\n",
      "1.79537686227\n",
      "1.79569099857\n",
      "1.79598479066\n",
      "1.79625855163\n",
      "1.79651419418\n",
      "1.79675169907\n",
      "1.79697384237\n",
      "1.79718320605\n",
      "1.79737752027\n",
      "1.79755977153\n",
      "1.79773088199\n",
      "1.79789082522\n",
      "1.79804062257\n",
      "1.79818206806\n",
      "1.79831353572\n",
      "1.7984378728\n",
      "1.79855415973\n",
      "1.79866445885\n",
      "1.79876797665\n",
      "1.79886538365\n",
      "1.79895668404\n",
      "1.79904403602\n",
      "1.79912398588\n",
      "1.79920080627\n",
      "1.79927290317\n",
      "1.799341303\n",
      "1.79940741865\n",
      "1.79946663048\n",
      "1.79952503064\n",
      "1.79957970875\n",
      "1.79963022719\n",
      "1.79967986577\n",
      "1.7997252672\n",
      "1.7997693726\n",
      "1.7998094697\n",
      "1.79984959841\n",
      "1.79988659367\n",
      "1.79992047208\n",
      "1.7999528609\n",
      "1.79998558586\n",
      "1.80001485768\n",
      "1.80004349131\n",
      "1.80006986476\n",
      "1.80009441093\n",
      "1.80011858191\n",
      "1.80014230943\n",
      "1.80016375713\n",
      "1.8001845928\n",
      "1.80020331843\n",
      "1.80022196983\n",
      "1.8002388916\n",
      "1.80025532301\n",
      "1.80027219377\n",
      "1.80028756953\n",
      "1.80030072986\n",
      "1.80031542051\n",
      "1.80032815128\n",
      "1.80033966178\n",
      "1.80035058994\n",
      "1.80036198889\n",
      "1.80037317894\n",
      "1.80038311176\n",
      "1.80039337169\n",
      "1.80040128979\n",
      "1.8004100671\n",
      "1.80041744911\n",
      "1.80042624832\n",
      "1.80043319228\n",
      "1.80044068056\n",
      "1.80044672717\n",
      "1.8004534297\n",
      "1.80045885852\n",
      "1.80046576443\n",
      "1.80046997267\n",
      "1.80047637895\n",
      "1.80048070284\n",
      "1.80048508385\n",
      "1.80048929725\n",
      "1.80049400689\n",
      "1.80049763712\n",
      "1.80050207825\n",
      "1.80050624376\n",
      "1.80050983056\n",
      "1.80051218082\n",
      "1.8005149644\n",
      "1.80051833806\n",
      "1.80052084622\n",
      "1.80052348427\n",
      "1.80052608161\n",
      "1.80052866541\n",
      "1.80053089342\n",
      "1.80053300322\n",
      "1.80053583273\n",
      "1.80053698375\n",
      "1.80053914821\n",
      "1.80054095729\n",
      "1.80054256739\n",
      "1.800544758\n",
      "1.80054609073\n",
      "1.80054690999\n",
      "1.80054929935\n",
      "1.80054977234\n",
      "1.80055163766\n",
      "1.80055330798\n",
      "1.80055358351\n",
      "1.80055526985\n",
      "1.80055582788\n",
      "1.8005572689\n",
      "1.80055806113\n",
      "1.8005580869\n",
      "1.80055906252\n",
      "1.80056064307\n",
      "1.80056132432\n",
      "1.80056189747\n",
      "1.80056321231\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    B = 1\n",
    "    pre_train_accumulate = 1\n",
    "    for _ in range(500):\n",
    "        PrePortfolio = np.zeros([B,L])\n",
    "        PreReturn = np.zeros(B)\n",
    "        train_accumulate = 1\n",
    "        for i in range(len(logReturn_x0)/2/B):\n",
    "            historicalData = logReturn_x[i*B:(i+1)*B]\n",
    "            compareReturn = logReturn_x0[i*B:(i+1)*B]\n",
    "            currentReturn = sess.run(reward, {x: historicalData, y_: compareReturn, \\\n",
    "                                      previousPortfolio: PrePortfolio, previousReturn: PreReturn} )\n",
    "            train_accumulate = train_accumulate * (sess.run(-reward_minus,\\\n",
    "                                                {x: historicalData,y_: compareReturn, \\\n",
    "                                                 previousPortfolio: PrePortfolio, previousReturn: PreReturn}))\n",
    "            train_step.run(feed_dict={x: historicalData, y_: compareReturn,\\\n",
    "                                  previousPortfolio: PrePortfolio, previousReturn: PreReturn})\n",
    "            prePortfolio = sess.run(currentPortfolio, \\\n",
    "                               {x: historicalData,y_: compareReturn, \\\n",
    "                                                 previousPortfolio: PrePortfolio, previousReturn: PreReturn})\n",
    "            preReturn = currentReturn\n",
    "        if np.abs(train_accumulate - pre_train_accumulate)<1e-8:\n",
    "            break\n",
    "        else:\n",
    "            pre_train_accumulate = train_accumulate\n",
    "        print train_accumulate\n",
    "    test_accumulate = 1 \n",
    "    PrePortfolio = np.zeros([B,L])\n",
    "    PreReturn = np.zeros(B)\n",
    "    testReturn = []\n",
    "    for i in range(len(logReturn_x0)/2/B, len(logReturn_x0)/B):\n",
    "        historicalData = logReturn_x[i*B:(i+1)*B]\n",
    "        compareReturn = logReturn_x0[i*B:(i+1)*B]\n",
    "        currentReturn = sess.run(reward, {x: historicalData, y_: compareReturn, \\\n",
    "                                      previousPortfolio: PrePortfolio, previousReturn: PreReturn} )\n",
    "        testReturn.append(currentReturn)\n",
    "        test_accumulate = test_accumulate * (sess.run(-reward_minus,\\\n",
    "                                                {x: historicalData,y_: compareReturn, \\\n",
    "                                                 previousPortfolio: PrePortfolio, previousReturn: PreReturn}))\n",
    "        test_step.run(feed_dict={x: historicalData, y_: compareReturn,\\\n",
    "                                  previousPortfolio: PrePortfolio, previousReturn: PreReturn})\n",
    "        prePortfolio = sess.run(currentPortfolio, \\\n",
    "                               {x: historicalData,y_: compareReturn, \\\n",
    "                                                 previousPortfolio: PrePortfolio, previousReturn: PreReturn})\n",
    "        preReturn = currentReturn\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.80056320453 1.81968611733\n",
      "(72,)\n",
      "0.218189167\n",
      "[-0.014886335469782352, -0.055797234177589417, -0.04151482135057449, -0.012503153644502163, 0.05783998966217041, 0.012669534422457218, -0.10510943084955215, 0.054019056260585785, 0.019063789397478104, 0.011736541986465454, 0.0054995957762002945, 0.012253908440470695, 0.01374413538724184, 0.026423875242471695, -0.0281561017036438, -0.004826952237635851, 0.0018615698209032416, 0.06360967457294464, -0.025831026956439018, 0.15862196683883667, 0.06556577980518341, -0.02797495573759079, -0.008308368735015392, -0.07586748152971268, 0.04141828045248985, 0.010269846767187119, 0.04480123519897461, -0.008660349994897842, 0.016663767397403717, 0.02760113775730133, -0.012515262700617313, 0.026278560981154442, 0.017219431698322296, 0.055203359574079514, 0.002638779114931822, 0.016441741958260536, -0.020243743434548378, 0.015309805050492287, -0.0007549322908744216, -0.009834209457039833, 0.01891256496310234, -0.011778581887483597, 0.020354025065898895, 0.004530641250312328, -0.009410308673977852, -0.010464451275765896, 0.055150579661130905, 0.03073287010192871, 0.0095356535166502, 0.0015059743309393525, 0.0014449015725404024, 0.03247620910406113, 0.011887890286743641, -0.07060469686985016, -0.012189281173050404, -0.005856674630194902, -0.0341334268450737, 0.06060560420155525, 0.1607116460800171, 0.025319330394268036, -0.029818858951330185, -0.06122612953186035, -0.023384450003504753, 0.004857663065195084, 0.0066052647307515144, 0.03315635025501251, 0.04889357089996338, 0.010764895007014275, -0.027933157980442047, 0.0020124136935919523, 0.07494350522756577, 0.022149741649627686]\n"
     ]
    }
   ],
   "source": [
    "print train_accumulate, test_accumulate\n",
    "testReturn_cnn = [float(testReturn[i]) for i in xrange(len(testReturn))]\n",
    "print np.shape(testReturn_cnn)\n",
    "\n",
    "print np.mean(testReturn_cnn)/np.std(testReturn_cnn)\n",
    "print testReturn_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72,)\n"
     ]
    }
   ],
   "source": [
    " print np.shape(range(len(logReturn_x0)/2/B, len(logReturn_x0)/B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-07\n"
     ]
    }
   ],
   "source": [
    "print 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e4bc28642fd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "a = [1,2,3,4]\n",
    "print a-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting csv data from data/sp10/\n",
      "['ORCL.csv', 'EBAY.csv', 'INTU.csv', 'INTC.csv', 'ADSK.csv', 'FB.csv', 'SYMC.csv', 'NFLX.csv', 'GOOGL.csv', 'AAPL.csv']\n",
      "epoch0, the training accumulated return is 1.09061932492.\n",
      "epoch1, the training accumulated return is 1.09159474442.\n",
      "epoch2, the training accumulated return is 1.09257390596.\n",
      "epoch3, the training accumulated return is 1.09367822721.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-83a05b248aa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;31m# estimated period return for corresponding date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m \u001b[0mestimateReturn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstockPrice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-83a05b248aa4>\u001b[0m in \u001b[0;36mCNN\u001b[0;34m(stockPrice, Time, c)\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mcompareReturn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogReturn_x0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mcurrentReturn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhistoricalData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcompareReturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreviousPortfolio\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPrePortfolio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreviousReturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPreReturn\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mtrain_accumulate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_accumulate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mreward_minus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhistoricalData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcompareReturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreviousPortfolio\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPrePortfolio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreviousReturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPreReturn\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                 \u001b[0mtrain_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhistoricalData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcompareReturn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreviousPortfolio\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPrePortfolio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreviousReturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPreReturn\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mprePortfolio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrentPortfolio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhistoricalData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcompareReturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreviousPortfolio\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPrePortfolio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreviousReturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPreReturn\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhanruohan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhanruohan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1118\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhanruohan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1315\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1316\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhanruohan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhanruohan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1298\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1299\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from utils import dataUtil\n",
    "\n",
    "# weight initialization\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# convolution and pooling\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def avg_pool_4x1(x):\n",
    "    return tf.nn.avg_pool(x, ksize=[1, 1, 1, 1],\n",
    "                        strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def CNN(stockPrice, Time, c):\n",
    "    logreturn = dataUtil.logReturn(stockPrice)\n",
    "    N = 10 # depend on the N previous periods\n",
    "    # return for N previous periods, input, shape: [-1,L,N]\n",
    "    logReturn_x = dataUtil.logReturnMatrix(logreturn, N)\n",
    "    # return for current period\n",
    "    logReturn_x0 = logreturn[N:]\n",
    "    \n",
    "    L = len(stockPrice[0]) # L stocks\n",
    "    B = 1 # batch size\n",
    "    \n",
    "    # training and testing data\n",
    "    Time = np.array(Time) - 1 - N\n",
    "    TestIndex = Time\n",
    "    TrainIndex = range(Time[0])\n",
    "    train_x = [logReturn_x[i] for i in TrainIndex]\n",
    "    train_y = [logReturn_x0[i] for i in TrainIndex]\n",
    "    test_x = [logReturn_x[i] for i in TestIndex]\n",
    "    test_y = [logReturn_x0[i] for i in TestIndex]\n",
    "    \n",
    "    # get CNN model\n",
    "    \n",
    "    # placeholder\n",
    "    x = tf.placeholder(tf.float32, shape=[None, L, N])\n",
    "    x_data = tf.reshape(x, [-1,L,N,1]) # start from one channel\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, L])\n",
    "    previousPortfolio = tf.placeholder(tf.float32, shape=[None, L]) # portfolio for last time step\n",
    "    previousReturn = tf.placeholder(tf.float32, shape=[None]) # return for last time step\n",
    "    \n",
    "    # first convolution layer\n",
    "    W_conv1 = weight_variable([1, 3, 1, 10])\n",
    "    b_conv1 = bias_variable([10])\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_data, W_conv1) + b_conv1)\n",
    "    h_pool1 = avg_pool_4x1(h_conv1)\n",
    "    \n",
    "    # second convolutional layer\n",
    "    W_conv2 = weight_variable([1, 3, 10, 5])\n",
    "    b_conv2 = bias_variable([5])\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = avg_pool_4x1(h_conv2)\n",
    "\n",
    "    # densely connected layer 1\n",
    "    wsize1 = int(h_pool2.shape[2] * h_pool2.shape[3])\n",
    "    wsize2 = 1\n",
    "    W_fc1 = weight_variable([wsize1, wsize2] )\n",
    "    prePort = tf.reshape(previousPortfolio,[-1,1])\n",
    "    W_fc12 = weight_variable([1, wsize2])\n",
    "    b_fc1 = bias_variable([wsize2])\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, wsize1])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + tf.matmul(prePort, W_fc12) + b_fc1)\n",
    "    h_fc1_score = tf.reshape(h_fc1, [-1, L])\n",
    "    \n",
    "    # densely connected layer 2 \n",
    "    # readout layer\n",
    "    W_fc2 = weight_variable([L, L])\n",
    "    b_fc2 = bias_variable([L])\n",
    "    y_conv = tf.matmul(h_fc1_score, W_fc2) + b_fc2\n",
    "    \n",
    "    # produce portfolio\n",
    "    currentPortfolio = tf.nn.softmax(logits=y_conv)\n",
    "\n",
    "    # define loss function\n",
    "    reward0 = np.multiply(currentPortfolio, y_)\n",
    "    reward = tf.reduce_sum(reward0, 1)\n",
    "    # calculate return including transaction cost\n",
    "    flag = 0\n",
    "    for j in xrange(L):\n",
    "        tmp = currentPortfolio[:,j]-previousPortfolio[:,j]*tf.divide(tf.exp(x[:,j,-1]),(1.0+previousReturn))\n",
    "        reward = reward - c[j+1] * np.abs(tmp)\n",
    "        if tmp != 0:\n",
    "            flag = 1\n",
    "    if flag:\n",
    "        reward = reward - c[0]\n",
    "\n",
    "    # loss function: reward_minus\n",
    "    reward_minus = -tf.reduce_prod(reward+1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(reward_minus)\n",
    "    test_step = tf.train.AdamOptimizer(1e-4).minimize(reward_minus)\n",
    "    \n",
    "    # train and test model\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # train model\n",
    "        pre_train_accumulate = 1\n",
    "        for k in range(500):\n",
    "            PrePortfolio = np.zeros([B,L])\n",
    "            PreReturn = np.zeros(B)\n",
    "            train_accumulate = 1\n",
    "            for i in TrainIndex:\n",
    "                historicalData = logReturn_x[i*B:(i+1)*B]\n",
    "                compareReturn = logReturn_x0[i*B:(i+1)*B]\n",
    "                currentReturn = sess.run(reward, {x: historicalData, y_: compareReturn, previousPortfolio: PrePortfolio, previousReturn: PreReturn} )\n",
    "                train_accumulate = train_accumulate * (sess.run(-reward_minus,{x: historicalData,y_: compareReturn, previousPortfolio: PrePortfolio, previousReturn: PreReturn}))\n",
    "                train_step.run(feed_dict={x: historicalData, y_: compareReturn,previousPortfolio: PrePortfolio, previousReturn: PreReturn})\n",
    "                prePortfolio = sess.run(currentPortfolio, {x: historicalData,y_: compareReturn, previousPortfolio: PrePortfolio, previousReturn: PreReturn})\n",
    "                preReturn = currentReturn\n",
    "            if np.abs(train_accumulate - pre_train_accumulate)<1e-8:\n",
    "                break\n",
    "            else:\n",
    "                pre_train_accumulate = train_accumulate\n",
    "            print 'epoch{0}, the training accumulated return is {1}.'.format(k, train_accumulate)\n",
    "            \n",
    "        # test model\n",
    "        test_accumulate = 1 \n",
    "        PrePortfolio = np.zeros([B,L])\n",
    "        PreReturn = np.zeros(B)\n",
    "        testReturn = []\n",
    "        for i in TestIndex:\n",
    "            historicalData = logReturn_x[i*B:(i+1)*B]\n",
    "            compareReturn = logReturn_x0[i*B:(i+1)*B]\n",
    "            currentReturn = sess.run(reward, {x: historicalData, y_: compareReturn, previousPortfolio: PrePortfolio, previousReturn: PreReturn} )\n",
    "            testReturn.append(currentReturn)\n",
    "            test_accumulate = test_accumulate * (sess.run(-reward_minus, {x: historicalData,y_: compareReturn, previousPortfolio: PrePortfolio, previousReturn: PreReturn}))\n",
    "            test_step.run(feed_dict={x: historicalData, y_: compareReturn, previousPortfolio: PrePortfolio, previousReturn: PreReturn})\n",
    "            prePortfolio = sess.run(currentPortfolio,  {x: historicalData,y_: compareReturn,  previousPortfolio: PrePortfolio, previousReturn: PreReturn})\n",
    "            preReturn = currentReturn\n",
    "            \n",
    "    return testReturn\n",
    "\n",
    "\n",
    "\n",
    "# get data (date, stockPrice)\n",
    "dateSelected, stockPrice = dataUtil.getData()\n",
    "    \n",
    "# get time for baseline estimation  \n",
    "Time = range(10+(len(dateSelected)-10)/2+1,len(dateSelected)) \n",
    "\n",
    "# Date for estimated return period (startDate,endDate) =  (dateSelected[Time[i]-1],dateSelected[Time[i]])\n",
    "Date = [(dateSelected[i-1][0],dateSelected[i][0]) for i in Time]\n",
    "\n",
    "# parameters for transaction cost\n",
    "c = np.zeros(len(stockPrice[-1])+1) + 0.0001\n",
    "\n",
    "# estimated period return for corresponding date\n",
    "estimateReturn = CNN(stockPrice, Time, c)\n",
    "     \n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
